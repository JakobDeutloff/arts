\chapter{Basic radiative transfer theory}
 \label{sec:rte_theory}


\starthistory
  030305 & Copied from a compendium written by Patrick Eriksson.\\
\stophistory


 When dealing with atmospheric radiation a division can be made
 between two different wavelength ranges where the limit is found
 around 5 $\mu$m, i.e. one range consists of the near IR, visible and UV
 regions while the second range covers thermal and far IR and
 microwaves. The first reason to this division is the principal
 sources to the radiation in the two ranges, for wavelengths shorter
 than 5 $\mu$m the solar radiation is dominating while at longer
 wavelengths the thermal emission from the surface and the atmosphere
 is more important. A second reason is the importance of scattering
 but here it is impossible to give a fixed limit. Clouds are important
 scattering objects for most frequencies but at cloud free conditions
 scattering can in many cases be neglected for wavelengths $>$ 5 $\mu$m. If
 the atmosphere can be assumed to be in local thermodynamic
 equilibrium the radiative transfer can be simplified considerably,
 and this is a valid assumption for the IR region and microwaves but
 not for e.g. UV frequencies.
 
 The radiative transfer in the atmosphere must be adequately described
 in many situations, as when estimating rates of photochemical
 reactions, calculating radiative forcing in the atmosphere or
 evaluating an remote sensing observation. It is not totally
 straightforward to quantify the radiative transfer with good accuracy
 because the calculations can be very computationally demanding and
 many of the parameters needed are hard to determine. For example,
 situations when a great number of transitions or multiple scattering
 must be considered will cause long calculations while as a rule
 scattering is problematic to model because the shape and size
 distribution of the scattering particles are highly variable
 quantities.  
 
 If scattering can be neglected and the atmosphere is assumed to be in
 local thermodynamic equilibrium, the radiative transfer equation gets
 unusually simple. These assumptions will be made below and
 they are normally valid for the infrared region and longer
 wavelengths as in the microwave region. For these conditions the
 atmospheric absorption and emission are linked and the basic problem
 to determine the radiative transfer is to calculate the absorption.
 At the wavelengths considered rotational and vibrational transitions
 are the dominating absorbing processes.


\section{Blackbody radiation}
 \label{sec:rtetheory:planck}
 
 All natural bodies with a temperature $>$ 0 K emit thermal radiation.
 The thermal motion in the matter is translated by collisions to
 excitations in the molecules. The transition from the excited state
 to a lower state causes emission of electromagnetic radiation.
 Depending on the temperature the distribution of the emission will
 change. An ideal body that absorbs all incoming radiation is called a
 blackbody and its emittance follows Planck's formula: 

 \begin{equation}
   B(\lambda,T) = \frac{2\pi hc^2}{\lambda^5} \frac{1}{e^{hc/\lambda k_bT}-1}
  \label{eq:rtetheory:planck}
 \end{equation}
 where $B$ is the emitted radiation, $\lambda$ the wavelength, $T$ the 
 temperature, $h$ the Planck constant, $c$ the speed of light and $k_b$
 the Boltzmann constant. Equation~\ref{eq:rtetheory:planck} is shown in Figure 
 \ref{fig:rtetheory:planck} for some temperatures.

 \begin{figure}
  \begin{center}
   \includegraphics*[width=0.8\hsize]{rte_theory/fig_planck}
    \caption{The blackbody radiation as a function of wavelength for
             some temperatures.}
    \label{fig:rtetheory:planck}
  \end{center}
 \end{figure}   
                                       
 The maximum of the Planck formula is a function temperature and is
 given by the Wien's displacement law. The maximum of
 Equation~\ref{eq:rtetheory:planck} is found at: 

 \begin{equation}
   \lambda_{max} = \frac{K}{T}
  \label{eq:rtetheory:wien}
 \end{equation}
 where is $\lambda_{max}$ the wavelength of maximum emittance and $K
 =$~2.898\topowerten{-3} Km. Consequently the maximum is encountered
 at a shorter wavelength for a higher temperature as can be seen in
 Figure \ref{fig:rtetheory:planck}.
                                     
 No natural object can be said to be a perfect blackbody but the Sun
 and the Earth can approximately be treated as blackbodies with
 temperature of about 6000 and 290 K, respectively, to explain some
 basic conditions. Wien's displacement law gives maximum for the solar
 radiation at 0.55 $\mu$m while the Earth thermal radiation is maximal
 around 10 $\mu$m. The solar maximum coincides with a region of high
 atmospheric transmission and this explains why the
 evolution has placed the vision between about 400 - 700 nm, the
 amount of energy at surface level is maximal in this range.  
 
 If the radiation from the Sun is scaled to compensate for the
 attenuation due to the distance it will be found that the radiation
 from the Earth itself will dominate for wavelengths longer than about
 5 $\mu$m. This means, for example, that remote sensing techniques in
 the thermal IR and microwave region primarily detect thermal emission
 from the surface or the atmosphere while observations in the optical
 and UV regions use absorbed, scattered or reflected solar radiation.
 This also explains why gases that exhibit absorption between 5 - 50
 $\mu$m are called greenhouse gases, they absorb partly some of the
 outgoing radiation from the surface and the sea.


\section{General theory}
 \label{sec:rtetheory:gen_theory}

 The basic equation describing radiative transfer along a specific 
 direction is

 \begin{equation}
   \frac{dI(\nu)}{dl} = -k(l,\nu)I(\nu) + S(l,\nu)
  \label{eq:rtetheory:chand}
 \end{equation} 
 where $I$ is the intensity per unit area, $\nu$ the frequency, $l$
 the distance along the propagation path, $k$ the total absorption
 coefficient (summed over all species and transitions) and $S$ the
 source term. In this general expression both $k$ and $S$ include
 effects of scattering, i.e. energy lost and gained in the viewing
 direction due to scattering. The discussion will here be restricted
 to situations where the scattering can be neglected. This can be a
 valid assumption for cloud free conditions and wavelengths greater
 than a few micrometers. At microwave wavelengths scattering can
 normally be neglected also when clouds are present. For the
 frequencies considered and altitudes below about 75 km the molecules
 in the atmosphere can also be considered to be in local thermodynamic
 equilibrium. This implies that the de-excitation and excitation of a
 transition have the same probability and the absorption and emission
 coefficients will be equal.  The Kirchoff law then states that the
 emitted radiance, the source function, is

 \begin{equation}
   S = k(l,\nu)B(T(l),\nu)
  \label{eq:rtetheory:kirch}
 \end{equation}  
 For the conditions given, no scattering and local thermodynamic
 equilibrium, the radiative transfer equation is obtained by combining
 Equations \ref{eq:rtetheory:chand} and \ref{eq:rtetheory:kirch}. The resulting
 differential equation can be solved to give

 \begin{equation}
   I(\nu) = I_0(\nu)e^{-\int^h_0{k(l',\nu)dl'}} + 
     \int^h_0{k(l,\nu)B(T(l),\nu) e^{-\int^l_0{k(l',\nu)dl'}} dl}
  \label{eq:rtetheory:rte}
 \end{equation}  
 where the receiver is assumed to be placed at $l$~=~0 and $h$ is the
 distance along the path to the limit of the media. $I_0$ is the
 intensity at the point $h$ which can represent thermal emission from
 the surface, solar radiation at top of the atmosphere or cosmic
 background radiation depending on the observation geometry. When
 discussing radiative transfer the quantity optical depth, $\tau$, is
 commonly used and it is defined as

 \begin{equation}
   \tau(l,\nu) = \int^l_0{k(l',\nu)dl'} 
  \label{eq:rtetheory:tau}
 \end{equation}  
 and Equation \ref{eq:rtetheory:rte} can be written as
 
 \begin{equation}
   I(\nu) = I_0(\nu)e^{-\tau(h,\nu)dl'} + 
     \int^h_0{k(l,\nu)B(T(l),\nu) e^{-\tau(l',\nu)} dl}
  \label{eq:rtetheory:rte2}
 \end{equation}  
 The terms inside the integral found in this equation have a simple
 physical meaning, the radiation emitted at one point is $kBdl$ and this
 quantity is attenuated by the factor $e^{-\tau}$ before it reaches the
 observation point.


\section{Special solutions}
 \label{sec:rtetheory:special}
 
 If the total emission along the propagation path can be neglected
 compared to the transmitted part of the incoming radiation, the
 radiative transfer equation is simplified to the well known Beer-Lambert law:
 
 \begin{equation}
   I(\nu) = I_0(\nu)e^{-\tau(h,\nu)}
  \label{eq:rtetheory:beer}
 \end{equation}  
 This equation can for example be used when evaluating solar
 occultation observations.  
 
 If the temperature is constant through the medium studied (Fig.
 \ref{fig:rtetheory:layer}) the integral in Equation \ref{eq:rtetheory:rte} can be solved
 analytically:

 \begin{figure}
  \begin{center}
   \begin{minipage}[c]{0.4\textwidth}
    \centering
    \caption{Schematic picture of the radiative transfer through a medium with
             constant temperature.}
    \label{fig:rtetheory:layer}
   \end{minipage}%
   \hspace{0.05\textwidth}%
   \begin{minipage}[c]{0.50\textwidth}
    \centering
    \includegraphics*[width=0.99\hsize]{rte_theory/fig_layer}
   \end{minipage}
  \end{center}
 \end{figure}   
  
 \begin{equation}
   I^{out} = I^{in}e^{-\tau} + B(T,\nu)(1-e^{-\tau})
  \label{eq:rtetheory:layer}
 \end{equation}  
 where is $\tau$ the total optical thickness of the medium. Two
 special cases can be distinguished. If the layer is totally optically
 thick ($\tau \to \infty$) then $I^{in}$ is totally absorbed and
 $I^{out} = B$, the medium emits as a blackbody. If the layer has no
 absorption ($\tau=0$) then Equation \ref{eq:rtetheory:layer} gives
 $I^{out} = I^{in}$ as expected.
 
 In microwave radiometry the measured intensity is normally presented
 by means of the brightness temperature, $T_b$. This quantity is
 derived from the Rayleigh-Jeans approximation of the Planck function:

 \begin{equation}
   B(T,\nu) \approx \frac{2\nu^2k_bT}{c^2} = \frac{2k_bT}{\lambda^2}
  \label{eq:rtetheory:rayjean}
 \end{equation}  
 This equation is valid when $h\nu \ll kT$ which is the case in the
 microwave region due to the relatively low frequencies. If the
 temperature is 50 K, $hv$ equals $kT$ at 1.04 THz. The important
 aspect of Equation \ref{eq:rtetheory:rayjean} is the linear relationship
 between the intensity and the physical temperature. The natural
 definition of brightness temperature, $T_b$, is then

 \begin{equation}
   T_b(\nu) = \frac{\lambda^2}{2k_bT} I(\nu)
  \label{eq:rtetheory:tb}
 \end{equation}  
 The difference between the brightness temperature and the physical
 temperature (corresponding to the actual intensity) increases with
 frequency which is exemplified in Figure \ref{fig:rtetheory:rayjean}. The
 differences for higher frequencies are certainly not negligible and
 the brightness temperature shall not be mistaken for the physical
 temperature. The important fact is that the brightness temperature
 has a linear relationship to the intensity and gives a more intuitive
 understanding of the magnitude of the emission. In the Rayleigh-Jeans
 limit Equation \ref{eq:rtetheory:rte} can be written as

 \begin{equation}
   T_b(\nu) = T_{b0}(\nu)e^{-\tau(h,\nu)dl'} + 
     \int^h_0{k(l,\nu)T(l) e^{-\tau(l',\nu)} dl}
  \label{eq:rtetheory:rte_tb}
 \end{equation}  

 \begin{figure}
  \begin{center}
    \includegraphics*[width=0.8\hsize]{rte_theory/fig_rayjean}
    \caption{The difference between the physical temperarature of a 
             blackbody and the equivalent brightness temperature
             calculated using the Rayleight-Jeans approximation.}
    \label{fig:rtetheory:rayjean}
  \end{center}
 \end{figure}   
